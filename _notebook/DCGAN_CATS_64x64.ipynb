{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>7532</td><td>application_1513605045578_5079</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hadoop30:8088/proxy/application_1513605045578_5079/\">Link</a></td><td><a target=\"_blank\" href=\"http://hadoop19:8042/node/containerlogs/container_e28_1513605045578_5079_01_000001/ID2223_Project_Gans_new__ejhly000\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "def wrapper(d_lr = 2e-4, g_lr = 2e-4):\n",
    "    import tensorflow as tf\n",
    "    import tensorflow.contrib.slim as slim\n",
    "    import numpy as np\n",
    "    import hops.hdfs as hdfs\n",
    "    from hops import tensorboard\n",
    "    import sys\n",
    "    import time\n",
    "    import os\n",
    "    \n",
    "    project_DIR = hdfs.project_path()\n",
    "    faces = \"hdfs:///Projects/ID2223_Project_Gans_new/faces/celeb_64x64.npy\"\n",
    "    catizh = \"hdfs:///Projects/ID2223_Project_Gans_new/Cats/Cats_64x64.npy\"\n",
    "    \n",
    "    with hdfs.get_fs().open_file(catizh, \"r\") as someFile:\n",
    "        importNumpyCats = np.load(someFile)\n",
    "    \n",
    "    CatImages = np.reshape(importNumpyCats, (-1,64,64,3))\n",
    "    \n",
    "    org_CatImages = CatImages\n",
    "    logdir = tensorboard.logdir()\n",
    "\n",
    "    if not os.path.exists(logdir + '/train'):\n",
    "        os.mkdir(logdir + '/train')\n",
    "    \n",
    "    image = CatImages[0]\n",
    "    IMAGE_XDIM = image.shape[0]\n",
    "    IMAGE_YDIM = image.shape[1]\n",
    "    IMAGE_ZDIM = image.shape[2]\n",
    "    \n",
    "    shape = len(CatImages[0]), IMAGE_XDIM, IMAGE_YDIM, IMAGE_ZDIM\n",
    "    out_channel_dim = shape[3]\n",
    "    \n",
    "    def normalizeImages(x):\n",
    "        # normalise to -1 to 1, tanH\n",
    "        v_min = x.min(axis=(1, 2), keepdims=True)\n",
    "        v_max = x.max(axis=(1, 2), keepdims=True)\n",
    "        return 2. * (x - v_min)/(v_max - v_min) - 1.\n",
    "    \n",
    "    def reScale(x):\n",
    "        return (x + 1)/2\n",
    "    \n",
    "    def lrelu(inputs, leak=0.2, scope=\"lrelu\"):\n",
    "        with tf.variable_scope(scope):\n",
    "            f1 = 0.5 * (1 + leak)\n",
    "            f2 = 0.5 * (1 - leak)\n",
    "            return f1 * inputs + f2 * abs(inputs)\n",
    "        \n",
    "    def convLayer(inputs, filters, kernel_size, strides, padding, activation, batch_normalization, training):\n",
    "        conv = tf.layers.conv2d(inputs=inputs, \n",
    "                               filters=filters, \n",
    "                               kernel_size=kernel_size, \n",
    "                               strides=strides, \n",
    "                               padding=padding)\n",
    "        if activation == \"relu\" and batch_normalization == True:\n",
    "            return tf.nn.relu(tf.layers.batch_normalization(conv, training=training))\n",
    "        elif activation ==\"relu\" and batch_normalization == False:\n",
    "            return tf.nn.relu(conv)\n",
    "        elif activation ==\"lrelu\" and batch_normalization == True:\n",
    "            return lrelu(tf.layers.batch_normalization(conv, training=training), 0.2)\n",
    "        elif activation ==\"lrelu\" and batch_normalization == False:\n",
    "            return lrelu(conv, 0.2)\n",
    "        else:\n",
    "            return conv\n",
    "    \n",
    "    def deConvLayer(inputs, filters, kernel_size, strides, padding, activation, batch_normalization, training):\n",
    "        deConv = tf.layers.conv2d_transpose(inputs=inputs, \n",
    "                                       filters=filters, \n",
    "                                       kernel_size=kernel_size, \n",
    "                                       strides=strides, \n",
    "                                       padding=padding)\n",
    "        if activation == \"relu\" and batch_normalization == True:\n",
    "            return tf.nn.relu(tf.layers.batch_normalization(deConv, training=training))\n",
    "        elif activation ==\"relu\" and batch_normalization == False:\n",
    "            return tf.nn.relu(deConv)\n",
    "        elif activation ==\"lrelu\" and batch_normalization == True:\n",
    "            return lrelu(tf.layers.batch_normalization(deConv, training=training), 0.2)\n",
    "        elif activation ==\"lrelu\" and batch_normalization == False:\n",
    "            return lrelu(deConv,0.2)\n",
    "        else:\n",
    "            return deConv\n",
    "        \n",
    "    def generator(x, out_channel_dim, isTrain=True, reuse=False):\n",
    "        with tf.variable_scope('G', reuse=reuse):\n",
    "            \n",
    "            h1 = deConvLayer(inputs=x, filters=1024, kernel_size=[4, 4], strides=(1,1), padding='VALID', \n",
    "                           activation = 'lrelu', batch_normalization = True, training=isTrain)\n",
    "            \n",
    "            h2 = deConvLayer(inputs=h1, filters=512, kernel_size=[4, 4], strides=(2,2), padding='SAME', \n",
    "                           activation = 'lrelu', batch_normalization = True, training=isTrain)\n",
    "            \n",
    "            h3 = deConvLayer(inputs=h2, filters=256, kernel_size=[4, 4], strides=(2,2), padding='SAME', \n",
    "                           activation = 'lrelu', batch_normalization = True, training=isTrain)\n",
    "            \n",
    "            h4 = deConvLayer(inputs=h3, filters=128, kernel_size=[4, 4], strides=(2,2), padding='SAME', \n",
    "                           activation = 'lrelu', batch_normalization = True, training=isTrain)\n",
    "            # out layer\n",
    "            h5 = tf.layers.conv2d_transpose(inputs= h4, filters=out_channel_dim, \n",
    "                                            kernel_size=[4, 4], strides=(2, 2), \n",
    "                                            padding='SAME')\n",
    "            o = tf.nn.tanh(h5)\n",
    "            tf.summary.image(\"Generated Images\", o , 9)\n",
    "            return o\n",
    "\n",
    "    def discriminator(x, isTrain=True, reuse=False):\n",
    "        with tf.variable_scope('D', reuse=reuse):\n",
    "            \n",
    "            h1 = convLayer(inputs=x, filters=128, kernel_size=[4, 4], strides=(2, 2), padding='SAME', \n",
    "                           activation='lrelu', batch_normalization=True, training=isTrain)\n",
    "            \n",
    "            h2 = convLayer(inputs=h1, filters=256, kernel_size=[4, 4], strides=(2, 2), padding='SAME', \n",
    "                           activation='lrelu', batch_normalization=True, training=isTrain)\n",
    "            \n",
    "            h3 = convLayer(inputs=h2, filters=512, kernel_size=[4, 4], strides=(2, 2), padding='SAME', \n",
    "                           activation='lrelu', batch_normalization=True, training=isTrain)\n",
    "            \n",
    "            h4 = convLayer(inputs=h3, filters=1024, kernel_size=[4, 4], strides=(2, 2), padding='SAME', \n",
    "                           activation='lrelu', batch_normalization=True, training=isTrain)\n",
    "            # out Layer\n",
    "            h5 = tf.layers.conv2d(inputs=h4, filters=1, kernel_size=[4, 4], strides=(1, 1), padding='VALID')\n",
    "            o = tf.nn.sigmoid(h5)\n",
    "            return o, h5\n",
    "\n",
    "    def getNextBatch(x, batch_size):\n",
    "        nImg = x.shape[0]\n",
    "        idx = np.random.randint(0, nImg,size = batch_size)\n",
    "        return x[idx,:]\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Defining Placeholder\n",
    "    input_real_images = tf.placeholder(shape=[None, 64, 64, 3], dtype=tf.float32, name='input_real_images') \n",
    "    input_z = tf.placeholder(dtype=tf.float32, shape=[None,1,1, 100], name='input_z')\n",
    "    learning_rate = tf.placeholder(dtype=tf.float32, name='learning_rate')\n",
    "    X_viz = tf.placeholder(tf.float32, shape=[3, 64, 64, 3]) # input Image\n",
    "    isTrain = tf.placeholder(dtype=tf.bool)\n",
    "\n",
    "    label_smoothing = 0.9\n",
    "    \n",
    "    # Defining the Networks\n",
    "    g_model = generator(input_z, out_channel_dim, isTrain)\n",
    "    d_model_real, d_logits_real = discriminator(input_real_images, isTrain)\n",
    "    d_model_fake, d_logits_fake = discriminator(g_model,isTrain, reuse=True)\n",
    "\n",
    "    # Defining Loss\n",
    "        # Discriminator Loss\n",
    "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_model_real) * label_smoothing ))\n",
    "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_model_fake)))\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "        # Generator Loss                                           \n",
    "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_model_fake) * label_smoothing))\n",
    "    \n",
    "    # Gathering Variables\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('D')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('G')]\n",
    "\n",
    "    # Defining Optimizer\n",
    "    d_beta1 = 0.5; g_beta1 = 0.5\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): \n",
    "        d_train_opt = tf.train.AdamOptimizer(d_lr, beta1=d_beta1).minimize(d_loss, var_list=d_vars)\n",
    "        g_train_opt = tf.train.AdamOptimizer(g_lr, beta1=g_beta1).minimize(g_loss, var_list=g_vars)\n",
    "    \n",
    "    # Training Parameters\n",
    "    steps = 1 \n",
    "    batch_size = 64\n",
    "    z_dim = 100\n",
    "    epochs = 1000\n",
    "    iteration = int(CatImages.shape[0] / batch_size)\n",
    "    save_step = 10\n",
    "    # Normalise to -1.0 to 1.0, tanH\n",
    "    CatImages = normalizeImages(org_CatImages)\n",
    "    # Start Training Session\n",
    "    with tf.Session() as sess:\n",
    "        # Values to be added to tensorboard\n",
    "        tf.summary.scalar('Generator_loss', g_loss)\n",
    "        tf.summary.scalar('Discriminator_loss', d_loss)\n",
    "        tf.summary.image(\"Input_images\", X_viz)\n",
    "        merged = tf.summary.merge_all()\n",
    "        # Define writer\n",
    "        writer_train = tf.summary.FileWriter( logdir + \"/train\", sess.graph )\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch_i in range(epochs):\n",
    "            for i in range(iteration):\n",
    "                batch_images = getNextBatch(CatImages, batch_size) # MiniBatch real img\n",
    "                batch_z = np.random.uniform(-1.0, 1.0, size=(batch_size,1,1, z_dim)) # MiniBatch noise\n",
    "                _ = sess.run(d_train_opt, feed_dict={input_real_images: batch_images, input_z: batch_z, isTrain:True}) # train Discriminator\n",
    "                _ = sess.run(g_train_opt, feed_dict={input_real_images: batch_images, input_z: batch_z, isTrain:True}) # train Generator\n",
    "                if steps == 1 or steps % save_step == 0: # record losses and retrevie images every ...save_step\n",
    "                    z_batch = np.random.uniform(-1.0, 1.0, size=[batch_size,1,1, z_dim]) # MiniBatch noise\n",
    "                    x_vizu_3 = reScale(getNextBatch(batch_images, 3)) # Example training images from current batch\n",
    "                    summary_train = sess.run(merged, feed_dict = {X_viz: x_vizu_3, input_real_images: batch_images, input_z: z_batch,isTrain:False})\n",
    "                    writer_train.add_summary(summary_train, steps)\n",
    "                steps += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hops import tflauncher\n",
    "tensorboard_hdfs_logdir = tflauncher.launch(spark, wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hops import tensorboard\n",
    "# Visualize all TensorBoard events for the jobs in the same TensorBoard\n",
    "tensorboard.visualize(spark, tensorboard_hdfs_logdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
